import json
from difflib import SequenceMatcher

import pandas

from .writer import Writer
from src.dataset_conversion.data.data_structure import DataStructure
from ..data.file_change import FileChange

HEADER = ['index', 'Access Gained', 'Attack Origin', 'Authentication Required', 'Availability', 'CVE ID',
          'CVE Page', 'CWE ID', 'Complexity', 'Confidentiality', 'Integrity', 'Known Exploits', 'Publish Date',
          'Score', 'Summary', 'Update Date', 'Vulnerability Classification', 'add_lines', 'codeLink', 'commit_id',
          'commit_message', 'del_lines', 'file_name', 'files_changed', 'func_after', 'func_before', 'lang',
          'lines_after',
          'lines_before', 'parentID', 'patch', 'project', 'project_after', 'project_before', 'target',
          'vul_func_with_fix', 'processed_func', 'flaw_line', 'flaw_line_index']


class BigVulLineVulWriter(Writer):
    def write_file(self):
        with open(self.file_path, 'w') as output_file:
            for n, element in enumerate(self.reader.read_file()):
                field = self.convert_to_big_vul(element)
                if n == 0:
                    field.to_csv(output_file, header=HEADER, index=False)
                else:
                    field.to_csv(output_file, header=False, index=False)

    def convert_files_changed(self, files_changed: list[FileChange]) -> str:
        result = '<_**next**_>'.join(json.dumps(file.dict()) for file in files_changed)
        return result

    def calculate_flaw_line(self, vulnerable_function: str, fixed_function: str) -> tuple[list[str], list[int]]:
        s = SequenceMatcher(None, vulnerable_function.splitlines(True), fixed_function.splitlines(True))
        vulnerable_lines = []
        vulnerable_lines_index = []
        for x in s.get_opcodes():
            pass
        for change, vul_start, vul_end, fix_start, fix_end in s.get_opcodes():
            if change == 'delete' or change == 'replace':
                vulnerable_lines_index.extend(list(range(vul_start, vul_end)))
        for index, line in enumerate(vulnerable_function.split('\n')):
            if index in vulnerable_lines_index:
                vulnerable_lines.append(line)
        return vulnerable_lines, vulnerable_lines_index

    def convert_to_big_vul(self, field: DataStructure) -> pandas.DataFrame:
        if field.target and not field.flaw_line:
            field.flaw_line, field.flaw_line_index = self.calculate_flaw_line(field.func_before, field.func_after)
        if not field.processed_func:
            pass
            field.processed_func = '\n'.join(line.strip() for line in field.func_before.splitlines(True))
        data_dict = dict(
            zip(HEADER, [[field.index], [field.access_gained], [field.attack_origin], [field.authentication_required],
                         [field.availability], [field.cve_id], [field.cve_page], [field.cwe_id], [field.complexity],
                         [field.confidentiality], [field.integrity], [field.known_exploits], [field.publish_date],
                         [field.score], [field.summary], [field.update_date],
                         [field.vulnerability_classification],
                         [field.add_lines], [field.codeLink], [field.commit_id], [field.commit_message],
                         [field.del_lines], [field.file_name], [self.convert_files_changed(field.files_changed)],
                         [field.func_after],
                         [field.func_before], [field.lang], [field.lines_after], [field.lines_before],
                         [field.parentID], [field.patch], [field.project], [field.project_after],
                         [field.project_before], [field.target], [field.vul_func_with_fix], [field.processed_func],
                         ['/~/'.join(field.flaw_line) if field.flaw_line else None],
                         [','.join(map(str, field.flaw_line_index)) if field.flaw_line_index else None]]))
        return pandas.DataFrame.from_dict(data_dict)
